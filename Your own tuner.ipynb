{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install rdkit-pypi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12cPrTQTrTpR",
        "outputId": "3ed9f6e7-bc48-4b33-8c53-947c7eca94bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.7/dist-packages (2022.3.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0qmHjs3qPouC",
        "outputId": "cca20a89-96ff-420a-ecfa-0588e6fa002b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Nomenclature Name                          Molecular Structure     CMC\n",
              "59                 A     C=CC(=C)C=C-C=C-C=CCCCCSSSNSOCOCOCSSSCCC  1261.0\n",
              "60                 A  C=CC(=C)C=C-C=C-C=CCCCCSSSNSOCOCOCSSSCCCSSS  1462.0\n",
              "61                 A                              C=CC(=C)C=C-C=C   376.0\n",
              "62                 A                            C=CC(=C)C=C-C=C-S   447.0\n",
              "63                 A                          C=CC(=C)C=C-C=C-S-S   515.0\n",
              "64                 A                     C=CC(=C)C=C-C=C-S-S-CCCO   682.0\n",
              "65                 A                  C=CC(=C)C=C-C=C-S-S-CCCOCCC   681.0\n",
              "66                 A               C=CC(=C)C=C-C=C-S-S-CCCOCCCOOO   818.0\n",
              "67                 A            C=CC(=C)C=C-C=C-S-S-CCCOCCCOOOCCC   817.0\n",
              "68                 A                                  C=CC(=C)C=N   391.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48e91091-2106-4779-8516-f20957efa7e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nomenclature Name</th>\n",
              "      <th>Molecular Structure</th>\n",
              "      <th>CMC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-C=CCCCCSSSNSOCOCOCSSSCCC</td>\n",
              "      <td>1261.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-C=CCCCCSSSNSOCOCOCSSSCCCSSS</td>\n",
              "      <td>1462.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C</td>\n",
              "      <td>376.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-S</td>\n",
              "      <td>447.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-S-S</td>\n",
              "      <td>515.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-S-S-CCCO</td>\n",
              "      <td>682.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-S-S-CCCOCCC</td>\n",
              "      <td>681.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-S-S-CCCOCCCOOO</td>\n",
              "      <td>818.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=C-C=C-S-S-CCCOCCCOOOCCC</td>\n",
              "      <td>817.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>A</td>\n",
              "      <td>C=CC(=C)C=N</td>\n",
              "      <td>391.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48e91091-2106-4779-8516-f20957efa7e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48e91091-2106-4779-8516-f20957efa7e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48e91091-2106-4779-8516-f20957efa7e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import rdkit\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"boilingpoints.csv\")\n",
        "df=df.dropna(how=\"all\")\n",
        "df=df.iloc[:,:3]\n",
        "df[\"Nomenclature Name\"]=df.iloc[:,2]\n",
        "df[\"Molecular Structure\"]=df.iloc[:,1]\n",
        "df[\"CMC\"]=df.iloc[:,0]\n",
        "df=df[[\"Nomenclature Name\",\"Molecular Structure\",\"CMC\"]]\n",
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nrDCqYj5XS81"
      },
      "outputs": [],
      "source": [
        "def encoding(df):\n",
        "  encoded=[]\n",
        "  elements=[['c'], ['n'], ['o'], ['C'], ['N'], ['F'], ['='], ['O'], \n",
        "            ['('], [')'], ['1'],['2'],['#'],['Cl'],['/']]\n",
        "  enc = OneHotEncoder(handle_unknown='ignore')\n",
        "  enc.fit(elements)\n",
        "  enc.categories_\n",
        "  df1=df[\"Molecular Structure\"].apply(lambda x: pd.Series(list(x)))\n",
        "  for i in range(df1.shape[0]):\n",
        "    x=enc.transform(pd.DataFrame(df1.iloc[i,:]).dropna(how=\"all\").values).toarray()\n",
        "    y=np.zeros(((df1.shape[1]-x.shape[0]),len(elements)))\n",
        "    encoded.append(np.vstack((x,y)))\n",
        "  return encoded\n",
        "\n",
        "def encoded_generate_images(df):\n",
        "  listt=encoding(df)\n",
        "  plt.figure(figsize=(20,100))\n",
        "  for i in range(len(listt)):\n",
        "    plt.subplot(len(listt),5,i+1)\n",
        "    plt.imshow(listt[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WOnH21vgn4PJ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,MaxPool2D,Conv2D,Conv1D,Flatten,MaxPooling1D\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmNFyfcqtW6R",
        "outputId": "294db0b2-8845-457a-a491-c092d7a4a6a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69, 43, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X=encoding(df)\n",
        "X=np.array(X)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLgE7E1VuAOP",
        "outputId": "e07e27cd-174b-4f51-f7ac-067b0db1fcb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Y=df[\"CMC\"].values\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "4k1cs5ODsESB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n"
      ],
      "metadata": {
        "id": "ny7Bn2tyFnpF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tavJY2y7uLFM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=128, kernel_size=8, activation='relu',kernel_regularizer=\"l2\", input_shape=(43, 15)))\n",
        "    model.add(MaxPooling1D(pool_size=5))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(hp.Choice('units', [30, 50]), activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.005)\n",
        "    model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['accuracy'])\n",
        "    Model=model.fit(x=X_train,y=y_train,epochs=10,batch_size=16,validation_split=0.2)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ilrZp53NGI-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = ['10', '20', '30', '40', '50', '60']\n",
        "list2=['0.001','0.002','0.003','0.004','0.005','0.006']\n",
        "int(my_list[1])\n",
        "float(list2[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5DepI37AopK",
        "outputId": "651bbd63-e1ca-487b-fe1e-a8e40ec8d212"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_t = []\n",
        "K=[]\n",
        "K2=[]\n",
        "\n",
        "for k in range(1,5):\n",
        "    for S in range (1,5):\n",
        "\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=128, kernel_size=8, activation='relu',kernel_regularizer=\"l2\", input_shape=(43, 15)))\n",
        "        model.add(MaxPooling1D(pool_size=5))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(int(my_list[k]), activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "        optimizer=tf.keras.optimizers.Adam(lr=float(list2[S]))\n",
        "        model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
        "        Model=model.fit(x=X_train,y=y_train,epochs=50,batch_size=16,validation_split=0.2)\n",
        "        y_predtrain=model.predict(X_train)\n",
        "        MAE_train=abs(y_predtrain.reshape(y_train.shape)-y_train).sum()/y_train.shape\n",
        "        result_t += [(MAE_train,int(my_list[k]),float(list2[k]))]\n",
        "        K += [int(my_list[k])]\n",
        "        K2 += [float(list2[k])]\n",
        "result_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wzg2UTh0ZtC",
        "outputId": "7b54deca-bd1a-46f1-e8df-2ed5edd684b5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 3s 119ms/step - loss: 608.3292 - val_loss: 597.7756\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 606.4567 - val_loss: 595.3995\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 603.7203 - val_loss: 591.8183\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 599.6490 - val_loss: 586.5344\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 593.7806 - val_loss: 579.0072\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 585.3709 - val_loss: 568.6765\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 574.2093 - val_loss: 554.9594\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 558.9996 - val_loss: 537.2877\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 539.6916 - val_loss: 514.8982\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 516.4711 - val_loss: 487.2023\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 486.8534 - val_loss: 454.0760\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 451.9509 - val_loss: 414.9587\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 411.5084 - val_loss: 367.5935\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 359.6873 - val_loss: 311.7801\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 302.1658 - val_loss: 245.7681\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 230.8487 - val_loss: 169.2802\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 154.9317 - val_loss: 130.7174\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 117.8293 - val_loss: 142.8975\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 117.9684 - val_loss: 158.3761\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 130.5241 - val_loss: 169.7754\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 136.4628 - val_loss: 162.9679\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 130.5976 - val_loss: 150.3004\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 116.4518 - val_loss: 142.5159\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 107.1184 - val_loss: 132.1090\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 102.3361 - val_loss: 123.4824\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 100.2082 - val_loss: 121.9058\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 94.6368 - val_loss: 123.1069\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 98.4987 - val_loss: 124.0590\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 97.2944 - val_loss: 119.9429\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 91.5443 - val_loss: 118.2098\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 87.5861 - val_loss: 117.1331\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 88.8460 - val_loss: 117.6674\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 85.3527 - val_loss: 115.9559\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 84.4575 - val_loss: 113.6099\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 78.8857 - val_loss: 113.0294\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 79.2312 - val_loss: 112.8203\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 79.6273 - val_loss: 112.4279\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 78.2949 - val_loss: 111.1179\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 73.8283 - val_loss: 109.3631\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 71.4189 - val_loss: 108.1063\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 70.7796 - val_loss: 107.7666\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 69.7881 - val_loss: 107.8601\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 66.8961 - val_loss: 107.6661\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 67.9700 - val_loss: 106.7281\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 66.3881 - val_loss: 105.6918\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 65.5791 - val_loss: 104.0499\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 66.9786 - val_loss: 102.6292\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 65.8103 - val_loss: 101.9986\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 62.7223 - val_loss: 101.2409\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 62.3065 - val_loss: 100.9740\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 68ms/step - loss: 608.2029 - val_loss: 597.0063\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 605.2519 - val_loss: 592.4104\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 599.7657 - val_loss: 584.5251\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 590.4536 - val_loss: 571.7891\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 576.3770 - val_loss: 552.7896\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 555.1254 - val_loss: 526.2237\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 525.9408 - val_loss: 490.4201\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 486.9989 - val_loss: 442.8848\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 434.9725 - val_loss: 381.1924\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 367.5825 - val_loss: 303.4294\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 284.3500 - val_loss: 206.6980\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 180.8141 - val_loss: 129.2702\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 109.1369 - val_loss: 152.5087\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 124.7529 - val_loss: 179.9699\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 151.7480 - val_loss: 175.8105\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 140.3074 - val_loss: 154.7191\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 118.7271 - val_loss: 142.1505\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 108.6615 - val_loss: 127.8814\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 101.4092 - val_loss: 122.3955\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 97.1624 - val_loss: 120.1993\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 95.1561 - val_loss: 118.2308\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 92.5700 - val_loss: 116.7238\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 89.4723 - val_loss: 115.5192\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 87.8415 - val_loss: 116.4742\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 86.4426 - val_loss: 120.1134\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 93.5888 - val_loss: 121.9465\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 93.0867 - val_loss: 119.0583\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 84.4568 - val_loss: 110.7709\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 77.9297 - val_loss: 107.6801\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 73.8491 - val_loss: 105.7402\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 72.1481 - val_loss: 104.3406\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 67.3825 - val_loss: 103.0267\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 67.0350 - val_loss: 102.9346\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 63.5198 - val_loss: 102.0768\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 60.2523 - val_loss: 100.1876\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 60.7831 - val_loss: 98.4524\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 62.9990 - val_loss: 97.5474\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 66.7376 - val_loss: 98.7050\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 71.5573 - val_loss: 97.2445\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 65.5199 - val_loss: 94.5275\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 54.4552 - val_loss: 92.4601\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 53.6241 - val_loss: 91.6518\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 57.5760 - val_loss: 93.9637\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 64.8590 - val_loss: 92.6546\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 55.0170 - val_loss: 89.1107\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.8350 - val_loss: 89.2465\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 50.5120 - val_loss: 89.0926\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 49.0509 - val_loss: 89.1588\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 50.1651 - val_loss: 88.3109\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 49.3747 - val_loss: 87.3602\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 70ms/step - loss: 607.9140 - val_loss: 595.8364\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 603.6689 - val_loss: 588.7549\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 594.7866 - val_loss: 576.0234\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 580.1829 - val_loss: 555.6535\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 557.1561 - val_loss: 525.6709\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 523.7330 - val_loss: 483.8072\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 477.7477 - val_loss: 427.1180\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 415.1211 - val_loss: 351.3234\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 331.3163 - val_loss: 253.0394\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 224.4372 - val_loss: 142.2172\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 133.2618 - val_loss: 142.7376\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 115.7398 - val_loss: 152.0842\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 122.9103 - val_loss: 151.9559\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 120.6426 - val_loss: 146.2165\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 118.0122 - val_loss: 139.9299\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 108.5148 - val_loss: 125.2133\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 92.7322 - val_loss: 116.2465\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 93.8137 - val_loss: 115.1002\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 89.3863 - val_loss: 112.8289\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 81.6832 - val_loss: 109.9305\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 81.4316 - val_loss: 107.3843\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 77.0207 - val_loss: 105.8813\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 72.7717 - val_loss: 103.9835\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 71.4254 - val_loss: 103.3081\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 75.2333 - val_loss: 102.1730\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 72.7934 - val_loss: 99.2197\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 64.8433 - val_loss: 97.6678\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 66.0046 - val_loss: 96.5061\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 62.9783 - val_loss: 94.6686\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 61.1866 - val_loss: 93.5343\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 57.7848 - val_loss: 93.3832\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 53.5684 - val_loss: 91.7690\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 57.2982 - val_loss: 92.7414\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 63.6014 - val_loss: 91.0631\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 53.7435 - val_loss: 93.2455\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 54.7963 - val_loss: 94.9604\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 57.5703 - val_loss: 92.2878\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 46.8278 - val_loss: 89.9092\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 49.5418 - val_loss: 89.8349\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.3666 - val_loss: 90.0899\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 45.7154 - val_loss: 88.6146\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 45.7565 - val_loss: 88.4216\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 45.8076 - val_loss: 89.0506\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 43.5500 - val_loss: 88.6685\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 46.1499 - val_loss: 88.2785\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 43.3065 - val_loss: 87.4939\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 43.9754 - val_loss: 87.5431\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 43.4416 - val_loss: 88.0612\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 47.0704 - val_loss: 88.5002\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 45.7151 - val_loss: 86.1963\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 64ms/step - loss: 607.3114 - val_loss: 593.0682\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 599.2338 - val_loss: 579.0134\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 582.4584 - val_loss: 552.8205\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 551.6503 - val_loss: 509.9022\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 500.7856 - val_loss: 444.4026\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 427.1834 - val_loss: 350.2305\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 322.7957 - val_loss: 222.3838\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 185.3915 - val_loss: 131.9361\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 127.8177 - val_loss: 176.7997\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 149.4139 - val_loss: 180.0411\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 147.4329 - val_loss: 156.2346\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 117.7922 - val_loss: 127.9555\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 100.2286 - val_loss: 119.4076\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 92.0971 - val_loss: 117.0908\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 85.9510 - val_loss: 114.1769\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 80.8193 - val_loss: 110.9219\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 76.6185 - val_loss: 107.3644\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 74.2943 - val_loss: 104.3953\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 69.6583 - val_loss: 103.3338\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 71.6254 - val_loss: 101.5579\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 65.2671 - val_loss: 98.7024\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 61.0442 - val_loss: 97.4816\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 58.4881 - val_loss: 96.1309\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 58.6135 - val_loss: 95.1047\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 58.0987 - val_loss: 94.8428\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 52.8525 - val_loss: 93.9645\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 51.0454 - val_loss: 91.7963\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 54.4032 - val_loss: 90.4113\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 53.5033 - val_loss: 91.1886\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 49.9122 - val_loss: 91.8483\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 47.1681 - val_loss: 88.9879\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 49.0938 - val_loss: 90.0200\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 59.1494 - val_loss: 88.3074\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 50.5559 - val_loss: 88.6819\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 49.1759 - val_loss: 90.1244\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 48.2432 - val_loss: 85.8533\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 47.6458 - val_loss: 88.7295\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 46.8142 - val_loss: 86.2851\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 43.5326 - val_loss: 86.0714\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 43.0367 - val_loss: 84.1935\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 38.4658 - val_loss: 83.7036\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 39.3847 - val_loss: 82.9741\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 44.8857 - val_loss: 82.7499\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 44.9264 - val_loss: 80.8660\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 39.2810 - val_loss: 79.0035\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 36.9809 - val_loss: 78.9791\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 39.8635 - val_loss: 78.5674\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 34.7371 - val_loss: 79.4676\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 37.6780 - val_loss: 78.9315\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 35.3021 - val_loss: 78.0462\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 63ms/step - loss: 608.2374 - val_loss: 597.3043\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 605.8035 - val_loss: 594.1913\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 602.2730 - val_loss: 589.2803\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 596.6123 - val_loss: 581.9196\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 588.2310 - val_loss: 571.4673\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 576.6641 - val_loss: 556.9998\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 560.8943 - val_loss: 537.7774\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 539.6870 - val_loss: 512.9998\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 513.0546 - val_loss: 481.8298\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 479.4523 - val_loss: 443.1680\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 438.2674 - val_loss: 395.6972\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 388.2238 - val_loss: 338.6320\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 327.4427 - val_loss: 270.7543\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 254.4945 - val_loss: 188.7496\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 168.0864 - val_loss: 131.5964\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 118.0203 - val_loss: 145.1873\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 117.9948 - val_loss: 158.7123\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 127.4696 - val_loss: 159.2589\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 125.9863 - val_loss: 157.1202\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 121.8942 - val_loss: 149.1115\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 113.0525 - val_loss: 136.3893\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 105.3712 - val_loss: 123.2932\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 96.0224 - val_loss: 120.1795\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 100.8120 - val_loss: 121.2824\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 99.7558 - val_loss: 118.9452\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 95.6810 - val_loss: 117.0152\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 87.3064 - val_loss: 115.1430\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 89.4922 - val_loss: 113.6748\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 85.2307 - val_loss: 112.9148\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 82.5260 - val_loss: 111.4714\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 80.2684 - val_loss: 110.6127\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 78.9885 - val_loss: 110.1482\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 76.5297 - val_loss: 109.3540\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 75.2365 - val_loss: 108.9389\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 73.0535 - val_loss: 108.1274\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 69.2208 - val_loss: 107.9295\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 69.6306 - val_loss: 107.5206\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 69.5315 - val_loss: 106.0520\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 67.1035 - val_loss: 104.2429\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 67.8019 - val_loss: 103.7977\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 64.4904 - val_loss: 103.8395\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 61.5961 - val_loss: 102.6118\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 62.5264 - val_loss: 101.0473\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 60.5782 - val_loss: 99.9992\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 56.8372 - val_loss: 98.2296\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 58.5119 - val_loss: 96.6133\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 60.0767 - val_loss: 95.8733\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 63.6372 - val_loss: 96.5680\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 63.2494 - val_loss: 94.1398\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 54.5185 - val_loss: 93.7213\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 64ms/step - loss: 607.6686 - val_loss: 595.2917\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 602.8400 - val_loss: 588.0024\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 594.3309 - val_loss: 575.3368\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 579.8579 - val_loss: 555.6459\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 557.6842 - val_loss: 527.1650\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 526.1704 - val_loss: 486.8820\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 481.7176 - val_loss: 432.8010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 424.4915 - val_loss: 362.1561\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 345.9782 - val_loss: 270.4921\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 245.8476 - val_loss: 155.2279\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 133.7180 - val_loss: 138.8588\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 116.9038 - val_loss: 165.6006\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 133.6311 - val_loss: 161.6501\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 126.4231 - val_loss: 146.2440\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 110.4668 - val_loss: 132.2227\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 104.8379 - val_loss: 120.7427\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 98.3499 - val_loss: 118.7006\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 96.2515 - val_loss: 116.3257\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 92.4776 - val_loss: 114.1293\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 88.9575 - val_loss: 112.6936\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 85.5490 - val_loss: 110.6086\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 80.8005 - val_loss: 108.6752\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 76.0429 - val_loss: 107.4225\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 73.4564 - val_loss: 107.6074\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 74.8977 - val_loss: 106.9358\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 70.7534 - val_loss: 104.8330\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 69.5783 - val_loss: 102.8194\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 63.5793 - val_loss: 100.2949\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 64.1195 - val_loss: 99.1780\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 62.3556 - val_loss: 99.6258\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 64.7512 - val_loss: 99.3473\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 64.1598 - val_loss: 99.2681\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 66.2777 - val_loss: 97.0089\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 60.0439 - val_loss: 96.0742\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 62.0943 - val_loss: 95.1577\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 59.4979 - val_loss: 93.5719\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 53.2639 - val_loss: 91.5566\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 53.1343 - val_loss: 93.4994\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 58.5119 - val_loss: 90.2004\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.0487 - val_loss: 91.5476\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 55.1843 - val_loss: 92.6945\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 52.9588 - val_loss: 90.7285\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 49.1544 - val_loss: 88.7808\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 52.5657 - val_loss: 88.0366\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 47.8491 - val_loss: 89.5224\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 49.9214 - val_loss: 91.5317\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 60.7932 - val_loss: 91.6518\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 55.2996 - val_loss: 87.6399\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 43.9692 - val_loss: 86.0416\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 41.7469 - val_loss: 85.3719\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 68ms/step - loss: 607.9319 - val_loss: 595.6063\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 603.0159 - val_loss: 587.4692\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 593.3559 - val_loss: 572.0701\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 574.7355 - val_loss: 546.5770\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 545.5758 - val_loss: 507.5521\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 502.9355 - val_loss: 451.1906\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 439.8675 - val_loss: 372.8555\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 352.7723 - val_loss: 267.6148\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 239.7859 - val_loss: 142.1799\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 120.9871 - val_loss: 144.9532\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 118.6043 - val_loss: 154.2499\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 124.2140 - val_loss: 144.1613\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 115.8284 - val_loss: 122.7834\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 98.2556 - val_loss: 125.3413\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 115.1134 - val_loss: 136.0122\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 125.8006 - val_loss: 122.9265\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 93.3948 - val_loss: 115.3717\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 85.9579 - val_loss: 126.2532\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 100.0666 - val_loss: 134.0333\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 111.6773 - val_loss: 131.2289\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 103.7731 - val_loss: 114.7811\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 82.2758 - val_loss: 106.1515\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 70.4351 - val_loss: 106.6083\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 77.9635 - val_loss: 104.7627\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 69.4749 - val_loss: 102.5691\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 64.2226 - val_loss: 100.1082\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 63.0846 - val_loss: 98.9604\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 64.6231 - val_loss: 96.8470\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 61.3155 - val_loss: 96.3711\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.4646 - val_loss: 94.8815\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.2980 - val_loss: 92.7717\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 53.3833 - val_loss: 92.0838\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 56.2748 - val_loss: 91.8475\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 56.2272 - val_loss: 90.1812\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 49.7088 - val_loss: 87.6130\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 48.5531 - val_loss: 86.6414\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 49.8443 - val_loss: 86.2521\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 46.6159 - val_loss: 87.0458\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 47.1999 - val_loss: 85.7015\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 46.5490 - val_loss: 85.0780\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.5606 - val_loss: 86.0255\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 43.9425 - val_loss: 85.2666\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 44.5977 - val_loss: 85.0483\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.3226 - val_loss: 84.1346\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 45.0061 - val_loss: 85.0919\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 46.8738 - val_loss: 90.8021\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 55.3217 - val_loss: 91.5907\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 52.1863 - val_loss: 83.7269\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 43.0314 - val_loss: 83.0051\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 45.1682 - val_loss: 82.1217\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 66ms/step - loss: 607.4135 - val_loss: 593.0543\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 599.2336 - val_loss: 578.4817\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 580.6395 - val_loss: 550.3202\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 548.1145 - val_loss: 504.0434\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 495.2610 - val_loss: 433.4214\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 416.6311 - val_loss: 330.2168\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 300.6170 - val_loss: 186.2791\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 151.5364 - val_loss: 148.9193\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 137.8785 - val_loss: 206.4125\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 186.3931 - val_loss: 201.9238\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 162.2789 - val_loss: 158.5309\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 115.8464 - val_loss: 130.0649\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 101.8753 - val_loss: 125.8969\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 114.2942 - val_loss: 137.4719\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 133.8174 - val_loss: 126.1335\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 106.8006 - val_loss: 116.6395\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 89.4659 - val_loss: 114.7417\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 86.6798 - val_loss: 112.7271\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 84.6453 - val_loss: 110.7733\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 80.3487 - val_loss: 110.1605\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 75.9351 - val_loss: 108.1087\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 71.7134 - val_loss: 105.2935\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 70.8319 - val_loss: 103.1710\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 67.8710 - val_loss: 103.6093\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 66.3358 - val_loss: 103.3222\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 70.7684 - val_loss: 99.9642\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 61.9491 - val_loss: 96.4891\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 60.9910 - val_loss: 95.0928\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 55.6573 - val_loss: 94.2683\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 57.5906 - val_loss: 92.4681\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 52.1117 - val_loss: 91.4435\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 50.4454 - val_loss: 90.1955\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.4532 - val_loss: 89.9848\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 49.5172 - val_loss: 88.6759\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.0369 - val_loss: 87.8544\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 46.3375 - val_loss: 87.7831\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 48.9961 - val_loss: 88.5660\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 50.1380 - val_loss: 88.6420\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 44.2035 - val_loss: 86.2780\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 44.1798 - val_loss: 86.2472\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 44.5465 - val_loss: 86.3680\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.2201 - val_loss: 85.8100\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 41.8560 - val_loss: 86.6931\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 42.3226 - val_loss: 85.6111\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 41.8437 - val_loss: 87.5499\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 51.6963 - val_loss: 85.1256\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 43.5897 - val_loss: 86.9977\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 42.7875 - val_loss: 83.6806\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 46.0246 - val_loss: 87.5660\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 52.4198 - val_loss: 82.5093\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 67ms/step - loss: 608.2275 - val_loss: 597.3696\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 605.9515 - val_loss: 594.2743\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 602.3879 - val_loss: 589.3934\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 596.7625 - val_loss: 581.8865\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 588.3481 - val_loss: 570.8648\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 576.3683 - val_loss: 555.5120\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 558.7696 - val_loss: 534.7487\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 536.5058 - val_loss: 507.4711\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 506.4774 - val_loss: 472.9282\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 469.8172 - val_loss: 429.0023\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 422.5476 - val_loss: 375.2638\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 367.0202 - val_loss: 311.2708\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 297.4848 - val_loss: 233.1251\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 212.2204 - val_loss: 147.1062\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 135.5108 - val_loss: 134.2699\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 118.6113 - val_loss: 149.8906\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 119.7920 - val_loss: 149.5129\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 117.9840 - val_loss: 140.7699\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 109.7733 - val_loss: 134.1841\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 108.4753 - val_loss: 127.7603\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 102.0514 - val_loss: 121.2689\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 96.9897 - val_loss: 119.6871\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 94.8519 - val_loss: 117.8548\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 93.5552 - val_loss: 116.0923\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 89.3964 - val_loss: 115.1594\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 87.4775 - val_loss: 114.4384\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 85.1727 - val_loss: 113.1120\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 80.6079 - val_loss: 111.3074\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 79.2044 - val_loss: 109.5698\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 76.1130 - val_loss: 108.5789\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 76.2575 - val_loss: 107.4409\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 73.3269 - val_loss: 105.2488\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 70.5510 - val_loss: 102.3069\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 73.3330 - val_loss: 102.4598\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 77.7773 - val_loss: 103.8638\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 79.8918 - val_loss: 101.7572\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 75.0045 - val_loss: 97.1192\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 62.9290 - val_loss: 98.1067\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 70.7346 - val_loss: 99.0087\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 70.5682 - val_loss: 96.4881\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 60.3453 - val_loss: 94.4963\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 57.1031 - val_loss: 93.8747\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.1597 - val_loss: 93.2450\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 57.7485 - val_loss: 93.2318\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 57.0114 - val_loss: 91.3845\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 54.3457 - val_loss: 90.5018\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 56.4135 - val_loss: 89.8051\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 55.4227 - val_loss: 91.2417\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 51.8078 - val_loss: 91.6574\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 55.5676 - val_loss: 90.2491\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 65ms/step - loss: 607.7184 - val_loss: 595.4443\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 602.9044 - val_loss: 588.0151\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 594.0226 - val_loss: 574.8491\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 578.4827 - val_loss: 554.0078\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 555.7501 - val_loss: 523.3574\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 521.3647 - val_loss: 480.9508\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 474.8310 - val_loss: 423.2870\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 411.2227 - val_loss: 348.0342\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 327.6754 - val_loss: 248.4659\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 220.5539 - val_loss: 138.6941\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 119.6660 - val_loss: 153.1065\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 127.7941 - val_loss: 184.5472\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 155.5575 - val_loss: 180.3706\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 147.9969 - val_loss: 154.0409\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 114.9104 - val_loss: 129.4484\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 99.3805 - val_loss: 121.3970\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 97.2240 - val_loss: 122.0362\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 99.9651 - val_loss: 119.2072\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 90.9251 - val_loss: 116.6991\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 86.7506 - val_loss: 114.8666\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 84.4349 - val_loss: 112.6002\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 83.5667 - val_loss: 110.5397\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 79.6335 - val_loss: 108.7238\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 73.4737 - val_loss: 108.0475\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 71.5017 - val_loss: 106.6482\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 73.2758 - val_loss: 105.3724\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 72.0087 - val_loss: 103.6990\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 65.6481 - val_loss: 99.8607\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 67.7480 - val_loss: 99.4817\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 74.3188 - val_loss: 101.0826\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 72.6479 - val_loss: 98.3933\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 64.9377 - val_loss: 96.6677\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 60.4222 - val_loss: 96.0796\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 58.8443 - val_loss: 94.5631\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.9409 - val_loss: 91.6871\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 56.0197 - val_loss: 91.2116\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 58.0553 - val_loss: 90.4835\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 51.7945 - val_loss: 91.4620\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 50.7152 - val_loss: 92.5107\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 52.4135 - val_loss: 90.8898\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.2330 - val_loss: 88.6963\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.9143 - val_loss: 88.5543\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 46.9225 - val_loss: 89.1316\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 44.3314 - val_loss: 88.6166\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 44.6810 - val_loss: 87.4711\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 49.2177 - val_loss: 87.3351\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 41.7459 - val_loss: 86.9620\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 45.2821 - val_loss: 86.8124\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 45.5031 - val_loss: 86.1580\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 42.5749 - val_loss: 84.9255\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 69ms/step - loss: 607.9476 - val_loss: 595.6664\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 603.2056 - val_loss: 587.4784\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 593.1296 - val_loss: 572.0378\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 575.1967 - val_loss: 546.5043\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 545.1664 - val_loss: 507.2478\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 501.8489 - val_loss: 449.6433\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 437.2423 - val_loss: 368.7098\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 347.7041 - val_loss: 259.2238\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 225.3353 - val_loss: 137.8691\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 116.4693 - val_loss: 156.9645\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 136.7403 - val_loss: 196.5592\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 175.5437 - val_loss: 193.9716\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 156.8106 - val_loss: 149.6795\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 115.5593 - val_loss: 120.9705\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 97.7972 - val_loss: 126.5055\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 109.9555 - val_loss: 125.7179\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 102.7405 - val_loss: 115.7963\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 89.1407 - val_loss: 113.4038\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 83.1959 - val_loss: 112.4988\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 81.0932 - val_loss: 111.8543\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 74.6526 - val_loss: 109.4424\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 72.6611 - val_loss: 107.2290\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 73.5314 - val_loss: 107.2310\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 68.4848 - val_loss: 106.9978\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 67.9731 - val_loss: 104.8808\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 65.6383 - val_loss: 102.9479\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 63.0011 - val_loss: 100.0596\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 69.5381 - val_loss: 102.7030\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 76.6480 - val_loss: 100.8426\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 66.2256 - val_loss: 97.2874\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 58.4980 - val_loss: 98.5150\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 62.7483 - val_loss: 97.6980\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 59.4266 - val_loss: 96.5906\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 58.2218 - val_loss: 93.7878\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.8561 - val_loss: 97.5625\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 65.2325 - val_loss: 100.7582\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 80.0439 - val_loss: 99.0636\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 65.9254 - val_loss: 91.7994\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 49.0611 - val_loss: 89.2806\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.6451 - val_loss: 97.5376\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 68.0327 - val_loss: 96.5273\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 59.0216 - val_loss: 88.8257\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 46.3091 - val_loss: 94.8155\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 65.5205 - val_loss: 97.7410\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 66.8677 - val_loss: 92.3532\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 50.2081 - val_loss: 86.5951\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 44.0218 - val_loss: 86.2680\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 51.2054 - val_loss: 85.7811\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 47.7340 - val_loss: 83.7088\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 42.6579 - val_loss: 83.3627\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 72ms/step - loss: 607.3859 - val_loss: 592.4511\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 597.9227 - val_loss: 574.1943\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 575.6531 - val_loss: 538.5815\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 532.7297 - val_loss: 476.9579\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 460.1632 - val_loss: 380.2383\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 355.4700 - val_loss: 235.9608\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 188.4081 - val_loss: 138.7127\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 131.4120 - val_loss: 205.5058\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 199.3741 - val_loss: 215.6293\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 176.5329 - val_loss: 154.6107\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 120.5150 - val_loss: 119.8707\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 94.5280 - val_loss: 116.8813\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 96.2610 - val_loss: 117.9323\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 92.4281 - val_loss: 108.8180\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 77.5822 - val_loss: 105.4639\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 72.9247 - val_loss: 102.3308\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 66.3809 - val_loss: 98.2706\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 64.0343 - val_loss: 95.4560\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 57.8902 - val_loss: 94.8904\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 64.8120 - val_loss: 93.7752\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 54.4261 - val_loss: 90.9531\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 58.6119 - val_loss: 91.3516\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 50.2732 - val_loss: 90.3107\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 55.9131 - val_loss: 88.7202\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 49.2328 - val_loss: 89.1312\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 59.2590 - val_loss: 89.3738\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 53.3777 - val_loss: 85.6158\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 46.7728 - val_loss: 85.4093\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 42.8276 - val_loss: 84.9693\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 43.9112 - val_loss: 83.9282\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 42.6880 - val_loss: 83.5822\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 41.2771 - val_loss: 82.3039\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 45.5180 - val_loss: 81.7680\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 44.6595 - val_loss: 81.6814\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 47.0510 - val_loss: 80.6741\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 40.1820 - val_loss: 83.9463\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.4611 - val_loss: 80.4117\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 38.6412 - val_loss: 80.4683\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 41.1887 - val_loss: 78.6361\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 35.7967 - val_loss: 81.3565\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 44.2009 - val_loss: 79.1777\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 46.8254 - val_loss: 87.7175\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 53.1704 - val_loss: 79.1732\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 42.7512 - val_loss: 88.5987\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 51.9246 - val_loss: 79.9858\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 40.1610 - val_loss: 77.1334\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 38.2236 - val_loss: 76.5567\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 39.5180 - val_loss: 75.9114\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 37.0329 - val_loss: 75.1493\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 35.9028 - val_loss: 74.0693\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 68ms/step - loss: 608.1274 - val_loss: 596.9296\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 605.2736 - val_loss: 592.9348\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 600.5933 - val_loss: 586.2822\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 592.8291 - val_loss: 576.0323\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 581.1326 - val_loss: 561.1298\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 564.7581 - val_loss: 540.4265\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 542.0714 - val_loss: 512.5419\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 511.6987 - val_loss: 475.9912\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 471.3450 - val_loss: 429.5266\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 422.1123 - val_loss: 371.3347\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 359.7220 - val_loss: 299.1225\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 281.2350 - val_loss: 212.2700\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 187.9953 - val_loss: 136.2119\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 114.8084 - val_loss: 142.4247\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 117.7412 - val_loss: 156.3949\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 125.5874 - val_loss: 161.1647\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 126.9953 - val_loss: 151.0284\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 116.3377 - val_loss: 139.2100\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 108.3971 - val_loss: 129.4969\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 98.4313 - val_loss: 120.1682\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 93.2530 - val_loss: 120.0827\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 93.3079 - val_loss: 120.6370\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 92.5121 - val_loss: 118.3576\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 88.3832 - val_loss: 116.5503\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 83.3382 - val_loss: 114.7199\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 83.3761 - val_loss: 113.9633\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 79.8785 - val_loss: 113.4421\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 78.2944 - val_loss: 112.6579\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 75.9035 - val_loss: 111.3991\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 73.4368 - val_loss: 109.9532\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 72.2959 - val_loss: 109.4967\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 70.3919 - val_loss: 108.8756\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 71.0515 - val_loss: 106.9949\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 67.3518 - val_loss: 104.8187\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 65.1563 - val_loss: 103.6526\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 63.3155 - val_loss: 103.6438\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 68.0842 - val_loss: 104.5921\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 73.9943 - val_loss: 102.5375\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 65.9491 - val_loss: 100.3833\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 59.4066 - val_loss: 99.5671\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 59.7507 - val_loss: 99.5326\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 59.2402 - val_loss: 98.6918\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 57.6786 - val_loss: 98.4881\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 60.4188 - val_loss: 98.4205\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 62.1479 - val_loss: 97.8774\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 58.2076 - val_loss: 96.2735\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 55.2744 - val_loss: 95.3601\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 57.0119 - val_loss: 94.1882\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 59.9562 - val_loss: 93.5645\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.2971 - val_loss: 93.5439\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 67ms/step - loss: 607.4715 - val_loss: 595.0984\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 602.6927 - val_loss: 587.1771\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 593.0687 - val_loss: 573.1891\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 577.2255 - val_loss: 550.8226\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 551.4880 - val_loss: 517.6227\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 515.3068 - val_loss: 470.5944\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 463.5148 - val_loss: 407.2160\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 393.8819 - val_loss: 324.7459\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 305.5045 - val_loss: 219.3400\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 190.8891 - val_loss: 130.1460\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 113.5021 - val_loss: 155.6642\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 130.1575 - val_loss: 164.2773\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 128.1703 - val_loss: 149.1516\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 118.3411 - val_loss: 131.9428\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 103.8662 - val_loss: 124.8124\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 100.3338 - val_loss: 122.4273\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 97.4456 - val_loss: 120.4937\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 91.4721 - val_loss: 118.9567\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 89.5679 - val_loss: 117.9204\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 85.8651 - val_loss: 115.7912\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 81.6358 - val_loss: 111.8735\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 76.6537 - val_loss: 111.5070\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 80.0721 - val_loss: 109.5694\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 76.8549 - val_loss: 107.0652\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 67.3826 - val_loss: 103.8074\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 67.1281 - val_loss: 103.5710\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 74.6744 - val_loss: 105.4311\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 79.9737 - val_loss: 101.5035\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 68.1997 - val_loss: 97.6756\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 60.9418 - val_loss: 96.5603\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 60.2890 - val_loss: 94.9678\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 57.5378 - val_loss: 96.0184\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 60.7099 - val_loss: 96.3412\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 58.2677 - val_loss: 94.5635\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 53.6644 - val_loss: 91.9099\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 54.4637 - val_loss: 91.6077\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 48.9980 - val_loss: 92.7788\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 53.0627 - val_loss: 93.8467\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 51.9446 - val_loss: 90.7155\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 49.4945 - val_loss: 90.8685\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 53.4831 - val_loss: 88.8567\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 44.5803 - val_loss: 91.5738\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 57.7478 - val_loss: 95.9444\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 57.9034 - val_loss: 88.5310\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 40.3024 - val_loss: 89.4046\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 57.3141 - val_loss: 90.3870\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 56.2164 - val_loss: 86.5503\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 41.3129 - val_loss: 88.6111\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.8208 - val_loss: 88.8683\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 46.7689 - val_loss: 85.9854\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 75ms/step - loss: 607.6859 - val_loss: 594.6337\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 601.3971 - val_loss: 583.5674\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 587.3434 - val_loss: 562.1367\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 563.3151 - val_loss: 525.6995\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 520.1515 - val_loss: 468.9488\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 457.2818 - val_loss: 385.4835\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 363.2182 - val_loss: 267.9300\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 234.6061 - val_loss: 135.9475\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 113.4638 - val_loss: 157.1912\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 128.8196 - val_loss: 162.1439\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 128.5008 - val_loss: 139.0056\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 102.8793 - val_loss: 123.8923\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 97.8919 - val_loss: 122.1575\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 94.9207 - val_loss: 119.2878\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 86.5196 - val_loss: 116.9715\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 80.6410 - val_loss: 113.5144\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 82.1170 - val_loss: 111.3719\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 78.0214 - val_loss: 110.6395\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 75.7382 - val_loss: 110.5100\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 76.9886 - val_loss: 107.5945\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 64.2413 - val_loss: 104.1329\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 68.1193 - val_loss: 102.8566\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 63.5957 - val_loss: 103.5874\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 70.5259 - val_loss: 106.3314\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 75.8426 - val_loss: 103.9892\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 67.8224 - val_loss: 99.5136\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 58.9390 - val_loss: 97.2163\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 57.8389 - val_loss: 96.3834\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 56.7500 - val_loss: 96.3681\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 55.0563 - val_loss: 94.6128\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 55.4795 - val_loss: 94.2629\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 55.7476 - val_loss: 94.0216\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 53.8143 - val_loss: 91.7436\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 53.6094 - val_loss: 94.7594\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 51.8797 - val_loss: 91.0216\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 47.3589 - val_loss: 93.2160\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 56.2354 - val_loss: 92.8453\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 54.1846 - val_loss: 89.8563\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 39.0293 - val_loss: 89.5354\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 50.4513 - val_loss: 89.8317\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 45.7644 - val_loss: 88.5058\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 42.2796 - val_loss: 88.1496\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 42.3069 - val_loss: 87.0106\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 41.9977 - val_loss: 86.8725\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 40.1727 - val_loss: 86.7574\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 39.5471 - val_loss: 87.8602\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 48.6172 - val_loss: 87.9538\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 42.5827 - val_loss: 84.8209\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 40.1397 - val_loss: 84.5827\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 39.8557 - val_loss: 84.6701\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 72ms/step - loss: 607.5529 - val_loss: 592.4092\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 597.8204 - val_loss: 573.8878\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 574.4972 - val_loss: 535.3014\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 527.6430 - val_loss: 467.6500\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 448.3694 - val_loss: 360.1586\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 324.5576 - val_loss: 199.0636\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 158.5904 - val_loss: 144.8111\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 118.6766 - val_loss: 166.0044\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 134.2959 - val_loss: 149.6216\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 111.9189 - val_loss: 127.0497\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 92.5825 - val_loss: 125.3235\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 110.5919 - val_loss: 129.5578\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 103.8605 - val_loss: 115.5010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 84.4479 - val_loss: 123.3510\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 92.8468 - val_loss: 123.6863\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 88.9007 - val_loss: 107.5118\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 71.2587 - val_loss: 110.6023\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 85.8498 - val_loss: 105.5983\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 73.1102 - val_loss: 101.9831\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 64.1021 - val_loss: 98.4627\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 57.6122 - val_loss: 95.0299\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 59.2774 - val_loss: 92.3251\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 53.1385 - val_loss: 90.8757\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 48.1356 - val_loss: 88.7277\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 48.6110 - val_loss: 87.7144\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 51.5116 - val_loss: 86.9248\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 49.8511 - val_loss: 93.5451\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 66.8131 - val_loss: 97.8901\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 68.1836 - val_loss: 85.7347\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 47.2481 - val_loss: 85.1315\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 49.5900 - val_loss: 82.2944\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 46.1257 - val_loss: 86.1856\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 50.3646 - val_loss: 81.9658\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 42.7237 - val_loss: 81.5133\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 49.8717 - val_loss: 82.4034\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 48.1107 - val_loss: 83.1109\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 46.0815 - val_loss: 87.9580\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 44.7736 - val_loss: 79.7604\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 49.0787 - val_loss: 84.4211\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 50.2025 - val_loss: 79.8185\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 39.0040 - val_loss: 81.2106\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 38.8632 - val_loss: 83.3291\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 43.1880 - val_loss: 80.0323\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 39.9914 - val_loss: 78.0732\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 37.6418 - val_loss: 78.4039\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 36.7687 - val_loss: 78.6305\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 36.8132 - val_loss: 79.0437\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 35.6039 - val_loss: 76.8239\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 32.1265 - val_loss: 79.3639\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 34.9380 - val_loss: 75.9689\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([68.11287291]), 20, 0.002),\n",
              " (array([53.00211231]), 20, 0.002),\n",
              " (array([48.68593002]), 20, 0.002),\n",
              " (array([42.07721705]), 20, 0.002),\n",
              " (array([61.00079735]), 30, 0.003),\n",
              " (array([49.74833084]), 30, 0.003),\n",
              " (array([47.89834122]), 30, 0.003),\n",
              " (array([46.83685322]), 30, 0.003),\n",
              " (array([57.63814318]), 40, 0.004),\n",
              " (array([49.41294881]), 40, 0.004),\n",
              " (array([48.69791998]), 40, 0.004),\n",
              " (array([40.38931196]), 40, 0.004),\n",
              " (array([59.24680176]), 50, 0.005),\n",
              " (array([49.34886927]), 50, 0.005),\n",
              " (array([48.69729339]), 50, 0.005),\n",
              " (array([40.57797655]), 50, 0.005)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ptL494EfTJ",
        "outputId": "cba31a6e-0e91-4138-bb7a-2a0fc545851d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([73.86295968]),\n",
              " array([61.13738974]),\n",
              " array([48.18553674]),\n",
              " array([50.23683186]),\n",
              " array([66.40783194]),\n",
              " array([52.93475534]),\n",
              " array([46.45021175]),\n",
              " array([47.18095885]),\n",
              " array([69.78309725]),\n",
              " array([55.02774461]),\n",
              " array([58.70143009]),\n",
              " array([41.95299771]),\n",
              " array([60.82706766]),\n",
              " array([50.79654787]),\n",
              " array([46.60914681]),\n",
              " array([43.62713121])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(x=X_train,y=y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "__LlfAr79_NU",
        "outputId": "3180784a-441c-4962-e046-48e9f6a4e256"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean_absolute_error'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(history.params)\n",
        "# check the keys of history object\n",
        "print(history.history.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQx9VVh489KN",
        "outputId": "d8798932-4d9c-4b2f-ecb4-57aa2c2d23d6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 10, 'steps': 1}\n",
            "dict_keys(['loss'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.history)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyGjDxVy9Mak",
        "outputId": "d1f772a0-18e3-48a9-b965-ec0e8d535f6c"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7fde3e23f950>\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 36, 128)           15488     \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 7, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 7, 128)            0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 896)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 50)                44850     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,389\n",
            "Trainable params: 60,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predtrain=model.predict(X_train)\n",
        "y_predtest=model.predict(X_test)\n",
        "MAE_test=abs(y_predtest.reshape(y_test.shape)-y_test).sum()/y_test.shape\n",
        "MAE_train=abs(y_predtrain.reshape(y_train.shape)-y_train).sum()/y_train.shape\n",
        "print(\"Mean Absolute Error on Training Set = \",MAE_train.item())\n",
        "print(\"Mean Absolute Error on Test Set = \",MAE_test.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIVrzyCy0y0m",
        "outputId": "633f4372-6731-407e-e63a-2a97df93e2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on Training Set =  58.3032469718687\n",
            "Mean Absolute Error on Test Set =  65.0591561453683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_predtrain,y_train.reshape(62,1))\n",
        "plt.xlim([0,1000])\n",
        "plt.ylim([0,1000])\n",
        "y_train.shape\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "psDXV0zH0w5P",
        "outputId": "7b907019-d232-4601-9733-4fa6c4622e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7,)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner\n"
      ],
      "metadata": {
        "id": "KZ7u3y3yGWd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n"
      ],
      "metadata": {
        "id": "Db4ddr-iGTJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "        max_trials=4,   \n",
        "    directory='keras_tuner_dir1s',\n",
        "    project_name='keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxpyiX9MGOox",
        "outputId": "d71f9178-8d98-469f-a3eb-60e1849d6130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 237ms/step - loss: 606.5396 - accuracy: 0.0000e+00 - val_loss: 588.7385 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 592.8971 - accuracy: 0.0000e+00 - val_loss: 564.2092 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 562.5708 - accuracy: 0.0000e+00 - val_loss: 517.3839 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 507.4066 - accuracy: 0.0000e+00 - val_loss: 439.5171 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 416.8166 - accuracy: 0.0000e+00 - val_loss: 321.5225 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 285.1955 - accuracy: 0.0000e+00 - val_loss: 153.1477 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 133.6569 - accuracy: 0.0000e+00 - val_loss: 163.8076 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 155.4152 - accuracy: 0.0000e+00 - val_loss: 219.1977 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 189.8341 - accuracy: 0.0000e+00 - val_loss: 185.7517 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 141.4546 - accuracy: 0.0000e+00 - val_loss: 137.0493 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x=X_train,y=y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_model = tuner.get_best_models()[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gMxxs0IKGi7t",
        "outputId": "affcc41e-7bbe-45e2-c1eb-1bf6bee7720e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "50                |?                 |units\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 74ms/step - loss: 607.0784 - accuracy: 0.0000e+00 - val_loss: 590.7965 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 595.2107 - accuracy: 0.0000e+00 - val_loss: 568.8766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 568.2299 - accuracy: 0.0000e+00 - val_loss: 526.1843 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 518.1679 - accuracy: 0.0000e+00 - val_loss: 453.9980 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 434.1579 - accuracy: 0.0000e+00 - val_loss: 342.1698 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 308.5249 - accuracy: 0.0000e+00 - val_loss: 177.6768 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 146.5512 - accuracy: 0.0000e+00 - val_loss: 150.4728 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 123.7847 - accuracy: 0.0000e+00 - val_loss: 174.2722 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 142.9464 - accuracy: 0.0000e+00 - val_loss: 154.8160 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 116.2040 - accuracy: 0.0000e+00 - val_loss: 127.6363 - val_accuracy: 0.0000e+00\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 101.4301 - accuracy: 0.0000e+00 - val_loss: 124.6142 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 97.7710 - accuracy: 0.0000e+00 - val_loss: 123.9964 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 96.5524 - accuracy: 0.0000e+00 - val_loss: 123.2511 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 93.6772 - accuracy: 0.0000e+00 - val_loss: 122.2517 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 94.0870 - accuracy: 0.0000e+00 - val_loss: 120.9356 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 91.9003 - accuracy: 0.0000e+00 - val_loss: 119.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 88.1156 - accuracy: 0.0000e+00 - val_loss: 116.9822 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 82.0431 - accuracy: 0.0000e+00 - val_loss: 114.8083 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 76.7285 - accuracy: 0.0000e+00 - val_loss: 112.9656 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 78.6835 - accuracy: 0.0000e+00 - val_loss: 111.9985 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 80.1202 - accuracy: 0.0000e+00 - val_loss: 110.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 75.2835 - accuracy: 0.0000e+00 - val_loss: 108.2400 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 69.6938 - accuracy: 0.0000e+00 - val_loss: 107.5087 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 67.1857 - accuracy: 0.0000e+00 - val_loss: 106.8406 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 66.7802 - accuracy: 0.0000e+00 - val_loss: 105.7773 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 67.4385 - accuracy: 0.0000e+00 - val_loss: 104.0804 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 64.3632 - accuracy: 0.0000e+00 - val_loss: 101.7819 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 59.4972 - accuracy: 0.0000e+00 - val_loss: 99.1928 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 57.0702 - accuracy: 0.0000e+00 - val_loss: 97.3741 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 56.9389 - accuracy: 0.0000e+00 - val_loss: 96.1544 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 52.5767 - accuracy: 0.0000e+00 - val_loss: 95.3210 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 52.4473 - accuracy: 0.0000e+00 - val_loss: 94.4175 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 51.4151 - accuracy: 0.0000e+00 - val_loss: 92.9855 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 50.6236 - accuracy: 0.0000e+00 - val_loss: 92.0644 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 50.7155 - accuracy: 0.0000e+00 - val_loss: 91.6471 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 49.8503 - accuracy: 0.0000e+00 - val_loss: 90.7577 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 47.0716 - accuracy: 0.0000e+00 - val_loss: 89.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 44.5708 - accuracy: 0.0000e+00 - val_loss: 87.9341 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 46.7526 - accuracy: 0.0000e+00 - val_loss: 87.1049 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 46.3153 - accuracy: 0.0000e+00 - val_loss: 87.0324 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 40.6932 - accuracy: 0.0000e+00 - val_loss: 86.9355 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 42.1225 - accuracy: 0.0000e+00 - val_loss: 86.4626 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 42.0111 - accuracy: 0.0000e+00 - val_loss: 85.6996 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 40.9567 - accuracy: 0.0000e+00 - val_loss: 84.5431 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 39.5540 - accuracy: 0.0000e+00 - val_loss: 83.9564 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 39.1925 - accuracy: 0.0000e+00 - val_loss: 83.8185 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 39.1054 - accuracy: 0.0000e+00 - val_loss: 83.4400 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 36.6176 - accuracy: 0.0000e+00 - val_loss: 82.5718 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 37.0404 - accuracy: 0.0000e+00 - val_loss: 81.7026 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 37.7251 - accuracy: 0.0000e+00 - val_loss: 81.4239 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 34.8652 - accuracy: 0.0000e+00 - val_loss: 82.5912 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 36.5079 - accuracy: 0.0000e+00 - val_loss: 82.6920 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 36.7077 - accuracy: 0.0000e+00 - val_loss: 79.8676 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 34.8687 - accuracy: 0.0000e+00 - val_loss: 79.6697 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 34.9618 - accuracy: 0.0000e+00 - val_loss: 80.6007 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 34.7814 - accuracy: 0.0000e+00 - val_loss: 82.1736 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 37.7059 - accuracy: 0.0000e+00 - val_loss: 79.3648 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 35.1909 - accuracy: 0.0000e+00 - val_loss: 78.6681 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 33.4961 - accuracy: 0.0000e+00 - val_loss: 79.1473 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 31.9233 - accuracy: 0.0000e+00 - val_loss: 79.0092 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-b0fe1280a1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner_utils.py\u001b[0m in \u001b[0;36mconvert_to_metrics_dict\u001b[0;34m(results, objective, func_name)\u001b[0m\n\u001b[1;32m    240\u001b[0m     ):\n\u001b[1;32m    241\u001b[0m         raise TypeError(\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;34mf\"Expected the return value of {func_name} to be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0;34m\"a single float when `objective` is left unspecified. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;34mf\"Recevied return value: {results} of type {type(results)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected the return value of HyperModel.fit() to be a single float when `objective` is left unspecified. Recevied return value: <keras.callbacks.History object at 0x7fde3ec71f90> of type <class 'keras.callbacks.History'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQg37qvNwH7q",
        "outputId": "a8773e19-1bab-4a83-e371-1d64efb4741f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 36, 128)           15488     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 7, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 128)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 896)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                26910     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,429\n",
            "Trainable params: 42,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "best_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model=best_model .fit(x=X_train,y=y_train,epochs=50,batch_size=16,validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPl3Wg4GGFxg",
        "outputId": "05754707-3e03-4e95-a2b4-d5f37c644ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 153.6794 - accuracy: 0.0000e+00 - val_loss: 156.9438 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 113.3909 - accuracy: 0.0000e+00 - val_loss: 126.5211 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 100.6229 - accuracy: 0.0000e+00 - val_loss: 134.4518 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 136.1806 - accuracy: 0.0000e+00 - val_loss: 148.6976 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 135.2037 - accuracy: 0.0000e+00 - val_loss: 127.9621 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 103.4551 - accuracy: 0.0000e+00 - val_loss: 118.0461 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 90.7563 - accuracy: 0.0000e+00 - val_loss: 115.4674 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 87.2258 - accuracy: 0.0000e+00 - val_loss: 112.4751 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 79.5325 - accuracy: 0.0000e+00 - val_loss: 111.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 74.9151 - accuracy: 0.0000e+00 - val_loss: 109.8216 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 72.2577 - accuracy: 0.0000e+00 - val_loss: 106.5901 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 71.3898 - accuracy: 0.0000e+00 - val_loss: 104.9064 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 72.3887 - accuracy: 0.0000e+00 - val_loss: 102.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 69.3191 - accuracy: 0.0000e+00 - val_loss: 101.2849 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 60.2271 - accuracy: 0.0000e+00 - val_loss: 100.9605 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 61.5461 - accuracy: 0.0000e+00 - val_loss: 99.0968 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 57.8927 - accuracy: 0.0000e+00 - val_loss: 98.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 61.7974 - accuracy: 0.0000e+00 - val_loss: 97.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 63.4236 - accuracy: 0.0000e+00 - val_loss: 95.4502 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 56.2186 - accuracy: 0.0000e+00 - val_loss: 93.3997 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 65.2940 - accuracy: 0.0000e+00 - val_loss: 94.8752 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 59.9514 - accuracy: 0.0000e+00 - val_loss: 89.6781 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 51.3324 - accuracy: 0.0000e+00 - val_loss: 93.9956 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 59.0768 - accuracy: 0.0000e+00 - val_loss: 88.2987 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 49.1502 - accuracy: 0.0000e+00 - val_loss: 91.2948 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 61.9647 - accuracy: 0.0000e+00 - val_loss: 93.1373 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 56.6179 - accuracy: 0.0000e+00 - val_loss: 86.5515 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 52.9248 - accuracy: 0.0000e+00 - val_loss: 89.0975 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 54.1580 - accuracy: 0.0000e+00 - val_loss: 85.4856 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 49.2860 - accuracy: 0.0000e+00 - val_loss: 84.2156 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 48.1083 - accuracy: 0.0000e+00 - val_loss: 84.4160 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 46.6232 - accuracy: 0.0000e+00 - val_loss: 84.4618 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 44.6390 - accuracy: 0.0000e+00 - val_loss: 83.0494 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 43.7318 - accuracy: 0.0000e+00 - val_loss: 82.2620 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 44.2022 - accuracy: 0.0000e+00 - val_loss: 80.6933 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 41.5696 - accuracy: 0.0000e+00 - val_loss: 80.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 41.1907 - accuracy: 0.0000e+00 - val_loss: 80.4419 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 45.5701 - accuracy: 0.0000e+00 - val_loss: 79.6175 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 41.1045 - accuracy: 0.0000e+00 - val_loss: 80.8136 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 47.8414 - accuracy: 0.0000e+00 - val_loss: 82.4913 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 41.8939 - accuracy: 0.0000e+00 - val_loss: 80.1656 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 47.4839 - accuracy: 0.0000e+00 - val_loss: 81.1940 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 44.0973 - accuracy: 0.0000e+00 - val_loss: 82.0743 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 43.9804 - accuracy: 0.0000e+00 - val_loss: 85.9382 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 46.2886 - accuracy: 0.0000e+00 - val_loss: 77.0162 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 41.6688 - accuracy: 0.0000e+00 - val_loss: 79.2939 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 41.0932 - accuracy: 0.0000e+00 - val_loss: 79.0929 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 44.3210 - accuracy: 0.0000e+00 - val_loss: 80.2608 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 43.0482 - accuracy: 0.0000e+00 - val_loss: 76.7246 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 39.0914 - accuracy: 0.0000e+00 - val_loss: 77.0201 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anBQTj5Y62oP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3750056d-a959-4e6f-9597-a2c102eb80be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-033268bf10f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_predtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMAE_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMAE_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Absolute Error on Training Set = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "y_predtrain=model.predict(X_train)\n",
        "y_predtest=model.predict(X_test)\n",
        "MAE_test=abs(y_predtest.reshape(y_test.shape)-y_test).sum()/y_test.shape\n",
        "MAE_train=abs(y_predtrain.reshape(y_train.shape)-y_train).sum()/y_train.shape\n",
        "print(\"Mean Absolute Error on Training Set = \",MAE_train.item())\n",
        "print(\"Mean Absolute Error on Test Set = \",MAE_test.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THWiOO0N5979"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_predtrain,y_train.reshape(62,1))\n",
        "plt.xlim([0,1000])\n",
        "plt.ylim([0,1000])\n",
        "y_train.shape\n",
        "y_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGY3gAAVIjhv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(Model.history[\"loss\"],color='r', linewidth=2.75, linestyle='-', marker='.', markersize=15,markerfacecolor='b',\n",
        "         markeredgecolor='black',\n",
        "         markeredgewidth=1,label=\"Training Loss\")\n",
        "plt.plot(Model.history['val_loss'],color='black', linewidth=2.75, linestyle='-', marker='.', markersize=15,markerfacecolor='brown',\n",
        "         markeredgecolor='black',\n",
        "         markeredgewidth=1,label=\"Validation Loss\")\n",
        "plt.xlabel(\"Number of Epochs\",size=20,color=\"black\")\n",
        "plt.ylabel(\"Loss\",size=20,color=\"black\")\n",
        "plt.xticks(size=20)\n",
        "plt.yticks(size=20)\n",
        "plt.title(\"Mean Absolute Error vs Number of Epochs\",size=20)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "1B3qbGpKnVmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import rdkit\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"boilingpointest (1).csv\")\n",
        "df=df.dropna(how=\"all\")\n",
        "df=df.iloc[:,:3]\n",
        "df[\"Nomenclature Name\"]=df.iloc[:,2]\n",
        "df[\"Molecular Structure\"]=df.iloc[:,1]\n",
        "df[\"CMC\"]=df.iloc[:,0]\n",
        "df=df[[\"Nomenclature Name\",\"Molecular Structure\",\"CMC\"]]\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "fZVG85L9niiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=encoding(df)\n",
        "X=np.array(X)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "f-nlplf3omEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predtrain=model.predict(X)"
      ],
      "metadata": {
        "id": "46XmA71joX_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predtrain"
      ],
      "metadata": {
        "id": "wFqzmmfspspg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnZrusg1MIDp"
      },
      "source": [
        "### Neural Network using Bond Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTXE-qJp3HMa"
      },
      "outputs": [],
      "source": [
        "mw={\"C\":12,\"c\":12,\"O\":16,\"o\":16,\"N\":14,\"F\":19}\n",
        "def Molecular_Weight(text):\n",
        "  Mass=[]\n",
        "  for elements in text:\n",
        "    if elements==\"C\":\n",
        "      Mass.append(mw[elements])\n",
        "    elif elements==\"c\":\n",
        "      Mass.append(mw[elements])\n",
        "    elif elements==\"o\":\n",
        "      Mass.append(mw[elements])\n",
        "    elif elements==\"O\":\n",
        "      Mass.append(mw[elements])\n",
        "    elif elements==\"F\":\n",
        "      Mass.append(mw[elements])\n",
        "    elif elements==\"N\":\n",
        "      Mass.append(mw[elements])  \n",
        "  return sum(Mass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBNC8xSYeoYe"
      },
      "outputs": [],
      "source": [
        "df[\"C_Atoms_Ring\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('c'))\n",
        "df[\"C_Atoms_Chain\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('C'))\n",
        "df[\"O_Atoms_Chain\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('O'))\n",
        "df[\"O_Atoms_Ring\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('o'))\n",
        "df[\"N_Double Bonds_Ring\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('c')/2)\n",
        "df[\"N_Double Bonds_Chain\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('='))\n",
        "df[\"Nitrogen_Atoms\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('N'))\n",
        "df[\"F_Atoms\"]=df[\"Molecular Structure\"].apply(lambda x: x.count('F'))\n",
        "df[\"MW\"]=df[\"Molecular Structure\"].apply(lambda x: Molecular_Weight(x))\n",
        "df[\"Total Number of Atoms\"]=df[\"Molecular Structure\"].apply(lambda x: len(x))\n",
        "df[\"Number of Single Bonds\"]=df[\"Molecular Structure\"].apply(lambda x:len(x)-x.count('=')-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slS7-juz24iB"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBi-i8M-3bz9"
      },
      "outputs": [],
      "source": [
        "X=df.loc[:,\"MW\":]\n",
        "Y=df[[\"CMC\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12QOPfyK30z_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA9zZFJb4TNH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "MRwV-qW2mk7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo3_USoJ4sf5"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(40, input_dim=3, activation=\"relu\",kernel_regularizer=\"l2\"))\n",
        "#model.add(Dense(20,activation=\"relu\",kernel_regularizer=\"l2\"))\n",
        "model.add(Dense(10,activation=\"relu\",kernel_regularizer=\"l2\"))\n",
        "#model.add(Dense(12, activation=\"relu\",kernel_regularizer=\"l2\"))\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55rDetUK49Z2"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlCWUNEe5HAy"
      },
      "outputs": [],
      "source": [
        "optimizer=tf.keras.optimizers.Adam(lr=0.09)\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
        "Model=model.fit(x=X_train,y=y_train,epochs=50,batch_size=64,validation_split=0.1)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wvt2Dfi5Xxs"
      },
      "outputs": [],
      "source": [
        "y_predtrain=model.predict(X_train)\n",
        "y_predtest=model.predict(X_test)\n",
        "print(\"Train Error = \",abs(y_predtrain.reshape(55)-y_train.values.reshape(55)).sum()/55)\n",
        "print(\"Unseen Test Error = \",abs(y_predtest.reshape(14)-y_test.values.reshape(14)).sum()/14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TajQ1AF4-A5E"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "fig = go.Figure(data=go.Scattergl(\n",
        "    x = y_predtrain.reshape(55),\n",
        "    y = y_train.values.reshape(55),\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        color=np.random.randn(14),\n",
        "        colorscale='Viridis',\n",
        "        line_width=2\n",
        "    )\n",
        "))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mEsSJWu-etS"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "fig = go.Figure(data=go.Scattergl(\n",
        "    x = y_predtest.reshape(14),\n",
        "    y = y_test.values.reshape(14),\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        color=np.random.randn(55),\n",
        "        colorscale='Viridis',\n",
        "        line_width=2\n",
        "    )\n",
        "))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T3Cqkd_AcVi"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.parse import quote\n",
        "\n",
        "def CIRconvert(ids):\n",
        "    try:\n",
        "        url = 'http://cactus.nci.nih.gov/chemical/structure/' + quote(ids) + '/smiles'\n",
        "        ans = urlopen(url).read().decode('utf8')\n",
        "        return ans\n",
        "    except:\n",
        "        return 'Did not work'\n",
        "\n",
        "identifiers  = ['Nevirapine', 'CTAB', 'Diethylsulfate', 'Diethyl sulfate', '50-78-2', 'Adamant']\n",
        "\n",
        "for ids in identifiers :\n",
        "    print(ids, CIRconvert(ids))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = open(\"inif.txt\", \"r\")\n",
        "\n",
        "for line in filename :\n",
        "    event = line\n",
        "    compounds = pcp.get_compounds(event, namespace='smiles') \n",
        "    match = compounds[0]\n",
        "    print(i,'$$$','the CID is',compounds,'$$$','The IUPAC name is',match.iupac_name,'$$$','for the SMILE',event)\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "0KMsdIaw5yc8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Prediction of CMCs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}